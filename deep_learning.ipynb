{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook for classifying claims and non-claims with BiLSTM and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scripts.load_corpus import DaxenbergerModified, StabGurevychCorpus\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, MaxPooling1D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Loading corpus from script class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                    text  target\n",
      "0     How can anyone expect children could do well a...       0\n",
      "1     Firstly , I think that the new high school wil...       1\n",
      "2     With technological advances , children have mo...       0\n",
      "3     Nowadays , many professors conduct research wh...       0\n",
      "4     In today ' s world there are many great and us...       0\n",
      "...                                                 ...     ...\n",
      "7046  Last but not least , knowledge is worth mentio...       1\n",
      "7047  To illustrate this point , I can write about m...       0\n",
      "7048  Consider a circumstance in which a student who...       0\n",
      "7049  in my opinion , reducing stress by listening t...       1\n",
      "7050  In addition , the basic economic course can al...       1\n",
      "\n",
      "[7051 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "#corpus_1 = StabGurevychCorpus()\n",
    "#df_all = corpus_1.df_all\n",
    "#print(df_all.head)\n",
    "\n",
    "corpus_2 = DaxenbergerModified()\n",
    "df_all = corpus_2.df_all\n",
    "print(df_all.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyperparameters used in BiLSTM and CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 25000\n",
    "embedding_dim = 300\n",
    "input_n = 50 # padded maximum length for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Encoding words from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoding = [one_hot(words,vocab_size) for words in df_all.iloc[:, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Padding to bring all the sequences to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ... 13661  3001 23758]\n",
      " [    0     0     0 ... 19048  9096   907]\n",
      " [    0     0     0 ...  8435 10505  4132]\n",
      " ...\n",
      " [    0     0     0 ...  9096  7101 22116]\n",
      " [    0     0     0 ...  9581  9392 11974]\n",
      " [    0     0     0 ...  8178  4951 21704]]\n"
     ]
    }
   ],
   "source": [
    "emb_doc = pad_sequences(encoding, padding='pre', maxlen=input_n)\n",
    "print(emb_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Converting data back to arrays and splitting it into train, validation, and \n",
    "test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4935, 50)\n",
      "(2924, 50)\n",
      "(2924,)\n",
      "(2116, 50)\n",
      "(1058, 50)\n",
      "(1058, 50)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(emb_doc)\n",
    "y = np.array(df_all.iloc[:, 1])\n",
    "\n",
    "random_seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y,\n",
    "                                                  train_size=0.7,\n",
    "                                                  random_state=random_seeds[4])\n",
    "print(X_train.shape)\n",
    "\n",
    "X_tr = np.column_stack((X_train, y_train))\n",
    "\n",
    "positive_entries = X_tr[X_tr[:, -1] == 1]\n",
    "negative_entries = X_tr[X_tr[:, -1] == 0]\n",
    "\n",
    "min_size = min(len(positive_entries), len(negative_entries))\n",
    "\n",
    "if len(positive_entries) > len(negative_entries):\n",
    "    positive_entries = positive_entries[:min_size]\n",
    "else:\n",
    "    negative_entries = negative_entries[:min_size]\n",
    "\n",
    "X_tr = np.concatenate((positive_entries, negative_entries))\n",
    "np.random.shuffle(X_tr)\n",
    "X_train = X_tr[:, :50]\n",
    "y_train = X_tr[:,-1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_rem.shape)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, \n",
    "                                                    test_size=0.5,\n",
    "                                                    random_state=42)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Defining BiLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 300)           7500000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 200)               320800    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7821001 (29.83 MB)\n",
      "Trainable params: 7821001 (29.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "bilstm_model = Sequential()\n",
    "bilstm_model.add(Embedding(vocab_size, embedding_dim, input_length=input_n)) \n",
    "bilstm_model.add(Bidirectional(LSTM(100)))\n",
    "bilstm_model.add(Dense(1, activation='sigmoid'))\n",
    "bilstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(bilstm_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Training the Bi-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 3s 358ms/step - loss: 0.6909 - accuracy: 0.5250 - val_loss: 0.6964 - val_accuracy: 0.4565\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 2s 278ms/step - loss: 0.6701 - accuracy: 0.5947 - val_loss: 0.7065 - val_accuracy: 0.4877\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 2s 281ms/step - loss: 0.6395 - accuracy: 0.6310 - val_loss: 0.6548 - val_accuracy: 0.5851\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 2s 284ms/step - loss: 0.5800 - accuracy: 0.7158 - val_loss: 0.7456 - val_accuracy: 0.4924\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 2s 264ms/step - loss: 0.5034 - accuracy: 0.7654 - val_loss: 0.6728 - val_accuracy: 0.6163\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 2s 268ms/step - loss: 0.3921 - accuracy: 0.8505 - val_loss: 0.6595 - val_accuracy: 0.6767\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 2s 276ms/step - loss: 0.3098 - accuracy: 0.8796 - val_loss: 0.7382 - val_accuracy: 0.6664\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 2s 269ms/step - loss: 0.2363 - accuracy: 0.9107 - val_loss: 0.6939 - val_accuracy: 0.7042\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 2s 272ms/step - loss: 0.1821 - accuracy: 0.9405 - val_loss: 0.6909 - val_accuracy: 0.7060\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 2s 270ms/step - loss: 0.1448 - accuracy: 0.9549 - val_loss: 0.7764 - val_accuracy: 0.7089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x292e67550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Evaluation with validation set:\n",
    "\n",
    "Prediction results:\n",
    "1 = claim\n",
    "0 = non-claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8338    0.7360    0.7819       750\n",
      "           1     0.5000    0.6429    0.5625       308\n",
      "\n",
      "    accuracy                         0.7089      1058\n",
      "   macro avg     0.6669    0.6894    0.6722      1058\n",
      "weighted avg     0.7367    0.7089    0.7180      1058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [value for value in (bilstm_model.predict(X_valid) > 0.5).astype(\"int32\")]\n",
    "cr = metrics.classification_report(y_valid.tolist(), y_pred, digits=4)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Evaluation with test set:\n",
    "\n",
    "Prediction results:\n",
    "1 = claim\n",
    "0 = non-claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8211    0.7429    0.7800       735\n",
      "           1     0.5191    0.6316    0.5698       323\n",
      "\n",
      "    accuracy                         0.7089      1058\n",
      "   macro avg     0.6701    0.6872    0.6749      1058\n",
      "weighted avg     0.7289    0.7089    0.7158      1058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = [value for value in (bilstm_model.predict(X_test) > 0.5).astype(\"int32\")]\n",
    "cr = metrics.classification_report(y_test.tolist(), y_pred_test, digits=4)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Defining CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 300)           7500000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 50, 128)           153728    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 25, 128)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 25, 64)            32832     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 12, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 12, 32)            8224      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 6, 32)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               49408     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7744449 (29.54 MB)\n",
      "Trainable params: 7744449 (29.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(vocab_size, embedding_dim, input_length=input_n))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.6907 - accuracy: 0.5466 - val_loss: 0.6756 - val_accuracy: 0.6109\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.6682 - accuracy: 0.5952 - val_loss: 0.6392 - val_accuracy: 0.6314\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.6044 - accuracy: 0.6864 - val_loss: 0.5763 - val_accuracy: 0.7099\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.4669 - accuracy: 0.8084 - val_loss: 0.5631 - val_accuracy: 0.7167\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 113ms/step - loss: 0.3096 - accuracy: 0.8784 - val_loss: 0.6521 - val_accuracy: 0.6451\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 116ms/step - loss: 0.1742 - accuracy: 0.9396 - val_loss: 0.8071 - val_accuracy: 0.6860\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.1082 - accuracy: 0.9643 - val_loss: 0.9142 - val_accuracy: 0.6451\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 112ms/step - loss: 0.0533 - accuracy: 0.9867 - val_loss: 0.9982 - val_accuracy: 0.6758\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.0317 - accuracy: 0.9939 - val_loss: 1.1203 - val_accuracy: 0.6860\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 112ms/step - loss: 0.0209 - accuracy: 0.9962 - val_loss: 1.4039 - val_accuracy: 0.6416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x298f16850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, validation_split=0.1, epochs=10, \n",
    "              batch_size=512, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Evaluation with validation set:\n",
    "\n",
    "Prediction results: \\\n",
    "1 = claim \\\n",
    "0 = non-claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8580    0.5720    0.6864       750\n",
      "           1     0.4247    0.7695    0.5473       308\n",
      "\n",
      "    accuracy                         0.6295      1058\n",
      "   macro avg     0.6414    0.6707    0.6169      1058\n",
      "weighted avg     0.7319    0.6295    0.6459      1058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [value for value in (cnn_model.predict(X_valid) > 0.5).astype(\"int32\")]\n",
    "cr = metrics.classification_report(y_valid.tolist(), y_pred, digits=4)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Evaluation with test set:\n",
    "\n",
    "Prediction results: \\\n",
    "1 = claim \\\n",
    "0 = non-claim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8356    0.5878    0.6901       735\n",
      "           1     0.4399    0.7368    0.5509       323\n",
      "\n",
      "    accuracy                         0.6333      1058\n",
      "   macro avg     0.6378    0.6623    0.6205      1058\n",
      "weighted avg     0.7148    0.6333    0.6476      1058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = [value for value in (cnn_model.predict(X_test) > 0.5).astype(\"int32\")]\n",
    "cr = metrics.classification_report(y_test.tolist(), y_pred_test, digits=4)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "corpus 1 \\\n",
    "model , macro F1, claim F1\n",
    "\n",
    "1st iteration \\\n",
    "BiLSTM: 0.6534 0.5829 \\\n",
    "CNN: 0.6122; 0.5393\n",
    "\n",
    "2nd iteration \\\n",
    "BiLSTM: 0.6405; 0.5816 \\\n",
    "CNN: 0.6184; 0.5420\n",
    "\n",
    "3rd iteration \\\n",
    "BiLSTM: 0.6417; 0.5605 \\\n",
    "CNN: 0.6061; 0.5593\n",
    "\n",
    "4th iteration \\\n",
    "BiLSTM: 0.6388; 0.5749 \\\n",
    "CNN: 0.6313; 0.5737\n",
    "\n",
    "5th iteration \\\n",
    "BiLSTM: 0.6446, 0.6098 \\\n",
    "CNN: 0.5876; 0.5586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM\n",
      "0.6437999999999999\n",
      "0.58194\n",
      "CNN\n",
      "0.61112\n",
      "0.55458\n"
     ]
    }
   ],
   "source": [
    "# average results for corpus 1\n",
    "\n",
    "bilstm_mean_macro_f1 = (0.6534 + 0.6405 + 0.6417 + 0.6388 + 0.6446) / 5\n",
    "bilstm_mean_claim_f1 = (0.5829 + 0.5816 + 0.5605 + 0.5749 + 0.6098) / 5\n",
    "\n",
    "cnn_mean_macro_f1 = (0.6122 + 0.6184 + 0.6061 + 0.6313 + 0.5876) / 5\n",
    "cnn_mean_claim_f1 = (0.5393 + 0.5420 + 0.5593 + 0.5737 + 0.5586) / 5\n",
    "\n",
    "print(\"BiLSTM\")\n",
    "print(bilstm_mean_macro_f1)\n",
    "print(bilstm_mean_claim_f1)\n",
    "print(\"CNN\")\n",
    "print(cnn_mean_macro_f1)\n",
    "print(cnn_mean_claim_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "corpus 2 \\\n",
    "model , macro F1, claim F1\n",
    "\n",
    "1st iteration \\\n",
    "BiLSTM: 0.6638; 0.5911 \\\n",
    "CNN: 0.6430; 0.5803\n",
    "\n",
    "2nd iteration \\\n",
    "BiLSTM: 0.6470; 0.5687 \\\n",
    "CNN: 0.5975; 0.5545\n",
    "\n",
    "3rd iteration \\\n",
    "BiLSTM 0.6223; 0.5345 \\\n",
    "CNN: 0.6263; 0.5316\n",
    "\n",
    "4th iteration \\\n",
    "BiLSTM: 0.6311; 0.5533 \\\n",
    "CNN: 0.6476; 0.5530\n",
    "\n",
    "5th iteration \\\n",
    "BiLSTM: 0.6568; 0.5413 \\\n",
    "CNN: 0.6314; 0.5569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM\n",
      "0.6442\n",
      "0.5577799999999999\n",
      "CNN\n",
      "0.62916\n",
      "0.55526\n"
     ]
    }
   ],
   "source": [
    "# average results for corpus 2\n",
    "\n",
    "bilstm_mean_macro_f1 = (0.6638 + 0.6470 + 0.6223 + 0.6311 + 0.6568) / 5\n",
    "bilstm_mean_claim_f1 = (0.5911 + 0.5687 + 0.5345 + 0.5533 + 0.5413) / 5\n",
    "\n",
    "cnn_mean_macro_f1 = (0.6430 + 0.5975 + 0.6263 + 0.6476 + 0.6314) / 5\n",
    "cnn_mean_claim_f1 = (0.5803 + 0.5545 + 0.5316 + 0.5530 + 0.5569) / 5\n",
    "\n",
    "print(\"BiLSTM\")\n",
    "print(bilstm_mean_macro_f1)\n",
    "print(bilstm_mean_claim_f1)\n",
    "print(\"CNN\")\n",
    "print(cnn_mean_macro_f1)\n",
    "print(cnn_mean_claim_f1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
